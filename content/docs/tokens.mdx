---
title: Tokenization
description: How LLM's break text into tokens and how to use them effectively.
imageUrl: "/blogs/tokens.png"
---

![token generation](/blogs/tokens.png)

import {Tokenizer} from "../components/tokenizer"

Large Language Models (LLMs) process text by breaking it down into smaller
units called tokens. 

We are charged per million tokens input and output by most LLM providers.
The context length is also measured in tokens.
So generally the lesser the tokens the better.

<Callout type="warn">
 Not completed yet, stay tuned! Try the interaractive tokenizer in the meantime.
</Callout>

<Tokenizer />
